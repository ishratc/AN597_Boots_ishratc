---
title: "ishratc_FinalHomeworkCode_05"
author: "Ishrat Chowdhury"
date: "November 6, 2019"
output: html_document
---

First let's load in our data
```{r}
library(curl)
library(ggplot2)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall19/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, stringsAsFactors = FALSE)
attach(d)
head(d)
```

Run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean).

```{r}
d$logHomeRange <- log(d$HomeRange_km2)
d$logFemaleBodyMass <- log(d$Body_mass_female_mean)
m<-lm(data=d, logHomeRange ~ logFemaleBodyMass)
m
m$coefficients #lets see the coefficeints 
#the intercept (B0) is -9.44 and the slope (B1) is 1.04
summary(m)
```

Now let's use bootstrapping to sample our data 1000 times. I first want to make a new data frame with just the 2 variables so it is easier to deal with.

```{r}
d2<-data.frame(d$logHomeRange, d$logFemaleBodyMass)
d2
```

To get the samples we need to use a function from {dplyr}

```{r}

library(dplyr)
d2<-tbl_df(d2)
k <- 1000 # number of samples
n <- 213 # let's go with the size of the orginal dataset, since we will allow replacement it should still generate different samples
s <- NULL # dummy variable to hold each sample
for (i in 1:k)
    s[[i]] <- sample_n(d2,size=n, replace=TRUE) # we want it with replacement, because we don't want reshuffling of the same dataset

```

now we have 1000 samples with varying numbers.

Let's apply the linear model to the sample.

```{r}
sample_model<-NULL
for (i in 1:1000) {
  sample_model[i]<-lm(data=s[[i]], formula=d.logHomeRange ~ d.logFemaleBodyMass)
}
sample_model #sample model now has the intercept and slope of all 1000 smaples 
```

Now we have to find the sampling distirbution for each of the B coefficients. Let's start with the interecept.

First we want to make a vector with all the interecept values

```{r}
intercepts<-NULL
for (i in 1:1000) {
  intercepts[i]<-(getElement(sample_model[[i]], "(Intercept)"))
}
intercepts # now we have all the intercepts from the samples, there is not exactl 1000 samples because some had a  NULL value for intercept
```

Now let's looks at the standard deviation of that

```{r}
interecpts_sd<-sd(intercepts)
interecpts_sd
```

This is a little bit less than the standard error form the lm function(.67). This makes sense because now there are more smaples so the error should be less. 

Let's do the the same for the slope.


```{r}
slopes<-NULL
for (i in 1:1000) {
  slopes[i]<-(getElement(sample_model[[i]], "d.logFemaleBodyMass"))
}
slopes # now we have all the intercepts from the samples, there is not exactl 1000 samples because some had a  NULL value for intercept
```

Now let's looks at the standard deviation of that

```{r}
slopes_sd<-sd(slopes)
slopes_sd
```

The same trend of lower standard error holds true for the slope.

Now let's find the CI for the previous model so we can compare the CI for the new model.

```{r}
ci <- confint(m, level = 0.95)  # using the results of lm()
ci
```

Now let's find the CI for our new model

Since the new model values are in the form of a vector we would have to do the ci manually.

```{r}

mi <- mean(intercepts)
mi

semi <- sd(intercepts)/sqrt(length(intercepts))
semi

lower <- mi - qnorm(1 - 0.05/2) * semi  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- mi + qnorm(1 - 0.05/2) * semi  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_intercept <- c(lower, upper)
ci_intercept

#now for slope

ms <- mean(slopes)
ms

sems <- sd(intercepts)/sqrt(length(slopes))
sems

lower <- ms - qnorm(1 - 0.05/2) * sems  # (1-alpha)/2 each in the upper and lower tails of the distribution
upper <- ms + qnorm(1 - 0.05/2) * sems  # (1-alpha)/2 each in the upper and lower tails of the distribution
ci_slope <- c(lower, upper)
ci_slope
```

Both of these are now in much narrower intervals. This makes sense since these are from the new sample so there is "more confidence" that the valyes would fall in between these two values. We can be more sure about the range of values now that we have a bigger sample.
